#!/usr/bin/env python3
"""
å½•éŸ³ç¨¿å¤„ç†Pipeline
è¾“å…¥å½•éŸ³ç¨¿txt -> ç”Ÿæˆé€å­—ç¨¿ -> è½¬æ¢ä¸ºJSON -> ç”ŸæˆHTMLæ–‡ç« 
"""

import os
import json
import yaml
import sys
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from generate_article import generate_wechat_article_html

def load_config():
    """åŠ è½½ç¯å¢ƒé…ç½®"""
    load_dotenv()
    
    api_key = os.getenv('API_KEY')
    base_url = os.getenv('BASE_URL')
    model_name = os.getenv('MODEL_NAME')
    
    if not api_key:
        raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®API_KEY")
    
    return {
        'api_key': api_key,
        'base_url': base_url,
        'model_name': model_name
    }

def load_prompts():
    """åŠ è½½prompté…ç½®"""
    with open('prompt.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config['prompts']

def call_llm(client, prompt, content, model_name):
    """è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹"""
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": content}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
        raise

def step1_transcript_to_verbatim(txt_path, config, prompts):
    """æ­¥éª¤1: å½•éŸ³ç¨¿è½¬é€å­—ç¨¿"""
    print("ğŸ¯ æ­¥éª¤1: å½•éŸ³ç¨¿è½¬é€å­—ç¨¿...")
    
    # è¯»å–å½•éŸ³ç¨¿
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            transcript = f.read()
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–å½•éŸ³ç¨¿æ–‡ä»¶: {e}")
        raise
    
    # è°ƒç”¨å¤§æ¨¡å‹
    client = OpenAI(api_key=config['api_key'], base_url=config['base_url'])
    prompt = prompts['transcript_to_verbatim']['content']
    
    verbatim = call_llm(client, prompt, transcript, config['model_name'])
    
    # ä¿å­˜é€å­—ç¨¿
    verbatim_path = txt_path.replace('.txt', '_verbatim.txt')
    with open(verbatim_path, 'w', encoding='utf-8') as f:
        f.write(verbatim)
    
    print(f"âœ… é€å­—ç¨¿å·²ä¿å­˜: {verbatim_path}")
    return verbatim, verbatim_path

def step2_verbatim_to_json(verbatim, config, prompts):
    """æ­¥éª¤2: é€å­—ç¨¿è½¬JSON"""
    print("ğŸ¯ æ­¥éª¤2: é€å­—ç¨¿è½¬JSON...")
    
    # è°ƒç”¨å¤§æ¨¡å‹
    client = OpenAI(api_key=config['api_key'], base_url=config['base_url'])
    prompt = prompts['verbatim_to_json']['content']
    
    json_content = call_llm(client, prompt, verbatim, config['model_name'])
    
    # è§£æJSON
    try:
        # æå–JSONå†…å®¹ï¼ˆå¦‚æœæ¨¡å‹è¿”å›äº†é¢å¤–çš„æ–‡æœ¬ï¼‰
        json_start = json_content.find('{')
        json_end = json_content.rfind('}') + 1
        if json_start != -1 and json_end > json_start:
            json_content = json_content[json_start:json_end]
        
        data = json.loads(json_content)
    except Exception as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        print("åŸå§‹è¿”å›å†…å®¹:")
        print(json_content)
        raise
    
    # ä¿å­˜JSON
    json_path = 'interview_data.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… JSONæ•°æ®å·²ä¿å­˜: {json_path}")
    return data, json_path

def step3_json_to_html(data):
    """æ­¥éª¤3: JSONè½¬HTML"""
    print("ğŸ¯ æ­¥éª¤3: JSONè½¬HTML...")
    
    # ç”ŸæˆHTML
    html_content = generate_wechat_article_html(data)
    
    # ä¿å­˜HTML
    html_path = 'interview_article.html'
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"âœ… HTMLæ–‡ç« å·²ç”Ÿæˆ: {html_path}")
    return html_path

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python pipeline.py <å½•éŸ³ç¨¿txtæ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    txt_path = sys.argv[1]
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(txt_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {txt_path}")
        sys.exit(1)
    
    print("ğŸš€ å¼€å§‹å¤„ç†pipeline...")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {txt_path}")
    
    try:
        # åŠ è½½é…ç½®
        config = load_config()
        prompts = load_prompts()
        
        # æ­¥éª¤1: å½•éŸ³ç¨¿è½¬é€å­—ç¨¿
        verbatim, verbatim_path = step1_transcript_to_verbatim(txt_path, config, prompts)
        
        # æ­¥éª¤2: é€å­—ç¨¿è½¬JSON
        data, json_path = step2_verbatim_to_json(verbatim, config, prompts)
        
        # æ­¥éª¤3: JSONè½¬HTML
        html_path = step3_json_to_html(data)
        
        print("\nğŸ‰ Pipelineæ‰§è¡Œå®Œæˆ!")
        print(f"ğŸ“ é€å­—ç¨¿: {verbatim_path}")
        print(f"ğŸ“‹ JSONæ•°æ®: {json_path}")
        print(f"ğŸŒ HTMLæ–‡ç« : {html_path}")
        
        # æ˜¾ç¤ºæ–‡ç« ä¿¡æ¯
        print(f"\nğŸ“Š æ–‡ç« ä¿¡æ¯:")
        print(f"   - å˜‰å®¾: {data.get('guest_name', 'N/A')}")
        print(f"   - å­—æ•°: {data.get('word_count', 'N/A')}")
        print(f"   - é¢„è®¡é˜…è¯»æ—¶é—´: {data.get('reading_time', 'N/A')}åˆ†é’Ÿ")
        print(f"   - ç« èŠ‚æ•°: {len(data.get('main_sections', []))}")
        
    except Exception as e:
        print(f"âŒ Pipelineæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()